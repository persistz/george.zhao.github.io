- date: 2023-12-25
  info: "Our paper on adversarial attack against speaker recognition systems is accepted by NDSS 2024."

- date: 2023-07-03
  info: "Join RealAI as a research engineer, focusing on adversarial machine learning and large model security."

- date: 2023-06-25
  info: Awarded title of Outstanding Graduates by Shanghai Ministry of Education.

- date: 2023-06-25
  info: "Ph.D. thesis defense: âœ…"

- date: 2023-06-25
  info: "Our paper on query-free black-box adversarial attack against speaker recognition systems is accepted by USENIX 2023."

- date: 2022-10-25
  info: "Win 2nd Place Prize in <a href='https://mlsec.io/'>MLSec Face Recognition Challenge</a>."

- date: 2022-07-25
  info: "Our paper on using adversarial attacks to accelerate neural network verification is accepted by SAS 2022."
  
- date: 2022-07-25
  info: "Our paper 'QVIP: An ILP-based  Formal Verification Approach for Quantized Neural Networks' is accepted by ASE 2022."

- date: 2022-06-25
  info: "I am currently a research assistant / visiting student in Singapore Management University, RISE Lab, co-advised by <a href='http://sunjun.site/'>Prof. Sun Jun</a>."
  
- date: 2022-04-25
  info: "Serve on the Artifact Evaluation Committee (AEC) of OSDI, Usenix ATC and ISSTA 2022."

- date: 2021-12-25
  info: "Awarded China national scholarship."
    
- date: 2021-11-25
  info: "Win Merit Prize in <a href='https://security.oppo.com/challenge/home.html'>OPPO 2021 Security AI Challenge</a>."

- date: 2021-06-25
  info: "Win the 3rd place in ACM MM 2021 Robust Logo Detection Competition among 36489 participating teams."

- date: 2021-05-25
  info: "Our paper about black-box adversarial attack and discretization problem is accepted by TDSC."

- date: 2021-04-26
  info: "Our paper 'BDD4BNN: A BDD-based Quantitative Analysis Framework for Binarized Neural Networks' is accepted by CAV 2021, the first author is <a href='http://s3l.shanghaitech.edu.cn/people/yedizhang/'>Yedi</a>."

- date: 2021-04-25
  info: "Our paper 'Attack as Defense: Characterizing Adversarial Examples using Robustness' is accepted by ISSTA 2021."

- date: 2021-03-25
  info: "Attacks on ML Defense Models. This competition is part of <a href='https://aisecure-workshop.github.io/amlcvpr2021/'>AML-CV</a> Workshop at CVPR 2021."